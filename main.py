import os
import json
import uuid
import asyncio
import nest_asyncio
from pathlib import Path

from telegram import Update
from telegram.ext import (
    Application,
    CommandHandler,
    MessageHandler,
    filters,
    ContextTypes,
)

from langchain_community.document_loaders import PyPDFLoader
from langchain_classic.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace
from langchain_classic.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate

from config import tg_token, hf_token

nest_asyncio.apply()
os.environ["HF_TOKEN"] = hf_token


DATA_DIR = Path("data/users")
DATA_DIR.mkdir(parents=True, exist_ok=True)

EMBEDDINGS_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

embeddings = HuggingFaceEmbeddings(
    model_name=EMBEDDINGS_MODEL,
    model_kwargs={"device": "cpu"},
)


def get_user_dir(user_id: int) -> Path:
    path = DATA_DIR / str(user_id)
    path.mkdir(parents=True, exist_ok=True)
    return path


def get_files_list_path(user_id: int) -> Path:
    return get_user_dir(user_id) / "files.json"


def get_doc_ids_path(user_id: int) -> Path:
    return get_user_dir(user_id) / "doc_ids.json"


def load_user_files(user_id: int):
    path = get_files_list_path(user_id)
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []


def save_user_files(user_id: int, files):
    with open(get_files_list_path(user_id), "w", encoding="utf-8") as f:
        json.dump(files, f, ensure_ascii=False, indent=2)


def load_doc_ids(user_id: int):
    path = get_doc_ids_path(user_id)
    if path.exists():
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}


def save_doc_ids(user_id: int, data):
    with open(get_doc_ids_path(user_id), "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def load_vectorstore(user_id: int):
    user_path = get_user_dir(user_id)
    if (user_path / "index.faiss").exists():
        return FAISS.load_local(
            folder_path=str(user_path),
            embeddings=embeddings,
            allow_dangerous_deserialization=True
        )
    return None


def save_vectorstore(user_id: int, vectorstore: FAISS):
    user_path = get_user_dir(user_id)
    vectorstore.save_local(str(user_path))


def build_qa_chain(vectorstore: FAISS):
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

    template = """
–¢—ã ‚Äî –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç —Å—Ç—Ä–æ–≥–æ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å: {question}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –æ—Ç–≤–µ—Ç—É:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
2. –ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ‚Äî –Ω–∞–ø–∏—à–∏:
   "–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
4. –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–º –∏ –ª–æ–≥–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–º.
5. –ï—Å–ª–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è —Å–≤–æ–π—Å—Ç–≤–∞, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏ –∏ —Ä–∞—Å–∫—Ä–æ–π –∫–∞–∂–¥–æ–µ.
6. –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É:
   - –ö—Ä–∞—Ç–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
   - –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ
   - –ü–µ—Ä–µ—á–µ–Ω—å —Å–≤–æ–π—Å—Ç–≤ (–µ—Å–ª–∏ –ø—Ä–∏–º–µ–Ω–∏–º–æ)
   - –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è

–û—Ç–≤–µ—Ç:
"""

    PROMPT = PromptTemplate(
        template=template,
        input_variables=["context", "question"],
    )

    endpoint = HuggingFaceEndpoint(
        repo_id="Qwen/Qwen2.5-7B-Instruct",
        temperature=0.1,
        max_new_tokens=1024,
        repetition_penalty=1.1,
        huggingfacehub_api_token=hf_token,
    )

    llm = ChatHuggingFace(llm=endpoint)

    return RetrievalQA.from_llm(
        llm=llm,
        retriever=retriever,
        chain_type="map_reduce",
        prompt=PROMPT,
        return_source_documents=True,
    )



async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ!\n\n"
        "–Ø –±–æ—Ç —Å –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω–æ–π PDF-–±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π üìö\n"
        "–ó–∞–≥—Ä—É–∂–∞–π—Ç–µ PDF-—Ñ–∞–π–ª—ã –∏ –∑–∞–¥–∞–≤–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å—ã."
    )


async def library(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    files = load_user_files(user_id)

    if not files:
        await update.message.reply_text("–í–∞—à–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—É—Å—Ç–∞.")
        return

    text = "üìö –í–∞—à–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞:\n\n"
    for i, file in enumerate(files, 1):
        text += f"{i}. {file}\n"

    await update.message.reply_text(text)


async def clear_library(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    user_path = get_user_dir(user_id)

    for file in user_path.glob("*"):
        file.unlink()

    await update.message.reply_text("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—á–∏—â–µ–Ω–∞.")


async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    document = update.message.document

    if not document.file_name.lower().endswith(".pdf"):
        await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ PDF —Ñ–∞–π–ª.")
        return

    await update.message.reply_text("–§–∞–π–ª –ø–æ–ª—É—á–µ–Ω. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é...")

    user_path = get_user_dir(user_id)
    file_path = user_path / document.file_name

    file = await document.get_file()
    await file.download_to_drive(str(file_path))

    loader = PyPDFLoader(str(file_path))
    documents = loader.load()

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=150,
    )

    docs = text_splitter.split_documents(documents)

    doc_ids = []
    for doc in docs:
        doc_id = str(uuid.uuid4())
        doc.metadata["source_file"] = document.file_name
        doc.metadata["doc_id"] = doc_id
        doc_ids.append(doc_id)

    vectorstore = load_vectorstore(user_id)

    if vectorstore:
        vectorstore.add_documents(docs, ids=doc_ids)
    else:
        vectorstore = FAISS.from_documents(docs, embeddings, ids=doc_ids)

    save_vectorstore(user_id, vectorstore)

    files = load_user_files(user_id)
    if document.file_name not in files:
        files.append(document.file_name)
        save_user_files(user_id, files)

    doc_ids_map = load_doc_ids(user_id)
    doc_ids_map[document.file_name] = doc_ids
    save_doc_ids(user_id, doc_ids_map)

    await update.message.reply_text(
        f"–î–æ–∫—É–º–µ–Ω—Ç '{document.file_name}' –¥–æ–±–∞–≤–ª–µ–Ω –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É."
    )


async def remove_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id

    files = load_user_files(user_id)
    doc_ids_map = load_doc_ids(user_id)

    if not files:
        await update.message.reply_text("–í–∞—à–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—É—Å—Ç–∞.")
        return

    if not context.args:
        await update.message.reply_text(
            "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n/remove –ù–û–ú–ï–†_–§–ê–ô–õ–ê\n\n"
            "–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–æ–º–µ—Ä–∞ –º–æ–∂–Ω–æ —á–µ—Ä–µ–∑ /library"
        )
        return

    try:
        file_index = int(context.args[0])
    except ValueError:
        await update.message.reply_text("–ù—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞ (—á–∏—Å–ª–æ).")
        return

    if file_index < 1 or file_index > len(files):
        await update.message.reply_text("–ù–µ–≤–µ—Ä–Ω—ã–π –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞.")
        return

    filename = files[file_index - 1]

    vectorstore = load_vectorstore(user_id)
    if not vectorstore:
        await update.message.reply_text("–ò–Ω–¥–µ–∫—Å –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return

    ids_to_delete = doc_ids_map.get(filename, [])

    if ids_to_delete:
        vectorstore.delete(ids=ids_to_delete)
        save_vectorstore(user_id, vectorstore)

    file_path = get_user_dir(user_id) / filename
    if file_path.exists():
        file_path.unlink()

    files.pop(file_index - 1)
    save_user_files(user_id, files)

    doc_ids_map.pop(filename, None)
    save_doc_ids(user_id, doc_ids_map)

    await update.message.reply_text(
        f"–§–∞–π–ª '{filename}' —É–¥–∞–ª—ë–Ω."
    )


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    vectorstore = load_vectorstore(user_id)

    if not vectorstore:
        await update.message.reply_text(
            "–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω PDF —Ñ–∞–π–ª."
        )
        return

    query = update.message.text

    docs_with_scores = vectorstore.similarity_search_with_score(query, k=5)

    if not docs_with_scores:
        await update.message.reply_text(
            "–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
        )
        return

    best_score = docs_with_scores[0][1]

    if best_score > 1.0:
        await update.message.reply_text(
            "–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
        )
        return

    qa_chain = build_qa_chain(vectorstore)

    await update.message.reply_text("–ò—â—É –æ—Ç–≤–µ—Ç...")

    try:
        response = qa_chain.invoke(query)

        if not response.get("source_documents"):
            await update.message.reply_text(
                "–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
            )
            return

        result = response["result"]

        if any('\u4e00' <= ch <= '\u9fff' for ch in result):
            await update.message.reply_text(
                "–í –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É."
            )
            return

        await update.message.reply_text(result)

    except Exception as e:
        await update.message.reply_text(f"–û—à–∏–±–∫–∞: {str(e)}")




async def main():
    application = Application.builder().token(tg_token).build()

    print("Bot started")

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("library", library))
    application.add_handler(CommandHandler("clear", clear_library))
    application.add_handler(CommandHandler("remove", remove_file))

    application.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    application.add_handler(
        MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message)
    )

    await application.run_polling()


if __name__ == "__main__":
    asyncio.run(main())
